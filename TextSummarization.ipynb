{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f791ab2-dc6c-4d17-8a95-b875694eed3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install transformers[torch]\n",
    "!pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007b02f5-9aea-4404-b332-489b88d6db37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcce00c-669a-432c-9745-faf84c90d4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"multi_news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a84c2fe-1cab-4a8f-99d3-bd7788294f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1a54a6-9301-4b5b-8b37-3fbdc9feff2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking the subset of the dataset for the finetuning purpose\n",
    "train_subset = dataset[\"train\"].select(range(10000))\n",
    "validation_subset = dataset[\"validation\"].select(range(1000))\n",
    "test_subset = dataset[\"test\"].select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ed4635-036c-40bf-9097-ff76b8354d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = 't5-small'\n",
    "tokenizer = T5Tokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626902a9-fe5a-42f8-aebf-e74fc7186e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    inputs = [\"summarize: \" + doc for doc in examples[\"document\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=512, truncation=True)\n",
    "\n",
    "    # Setup the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples[\"summary\"], max_length=150, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ff48cc-c1f0-4eb8-b6f6-72592f6bbc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize datasets\n",
    "tokenized_train = train_subset.map(preprocess_function, batched=True)\n",
    "tokenized_validation = validation_subset.map(preprocess_function, batched=True)\n",
    "tokenized_test = test_subset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6625801-c916-4f32-b2c2-6e2fba92bfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "model = T5ForConditionalGeneration.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853c206b-989e-4560-a291-236640e07349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data collator\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1aae04-adbc-4431-bd3d-a1987cc3dd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define compute_metrics function\n",
    "rouge = load_metric(\"rouge\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "\n",
    "    # Decode the predictions and labels\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n",
    "    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "\n",
    "    # Compute ROUGE scores\n",
    "    rouge_output = rouge.compute(predictions=pred_str, references=label_str, use_stemmer=True)\n",
    "\n",
    "    # Aggregate the ROUGE scores\n",
    "    result = {key: value.mid.fmeasure * 100 for key, value in rouge_output.items()}\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in pred_ids]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a437ea8b-06e0-47d6-bf17-a664a47b19d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seq2Seq training arguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./results\",             # Directory to save model checkpoints and logs\n",
    "    evaluation_strategy=\"epoch\",        # Evaluate the model at the end of each epoch\n",
    "    learning_rate=2e-5,                 # Learning rate for the optimizer\n",
    "    per_device_train_batch_size=16,     # Batch size for training\n",
    "    per_device_eval_batch_size=16,      # Batch size for evaluation\n",
    "    weight_decay=0.01,                  # Weight decay for regularization\n",
    "    save_total_limit=3,                 # Limit the total number of checkpoints saved\n",
    "    num_train_epochs=3,                 # Number of training epochs\n",
    "    predict_with_generate=True,         # Use generation mode for prediction\n",
    "    generation_max_length=150,          # Maximum length for generated sequences\n",
    "    generation_num_beams=4,             # Number of beams for beam search during generation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1670b0-d092-468d-a272-b40544479b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,                       # The model to be trained\n",
    "    args=training_args,                # Training arguments defined with Seq2SeqTrainingArguments\n",
    "    train_dataset=tokenized_train,     # The training dataset\n",
    "    eval_dataset=tokenized_validation, # The evaluation dataset\n",
    "    data_collator=data_collator,       # The data collator for processing data batches\n",
    "    tokenizer=tokenizer,               # The tokenizer used for preprocessing\n",
    "    compute_metrics=compute_metrics,   # The function to compute evaluation metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21c2f65-7e7b-4988-bb5b-c7aba4dc6396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b441d61-22b1-462f-bb78-9db3a4b7af67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on validation set\n",
    "trainer.evaluate()\n",
    "\n",
    "# Evaluate the model on test set\n",
    "test_results = trainer.evaluate(eval_dataset=tokenized_test)\n",
    "\n",
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc816f2-b1d7-4730-ba63-f581c2950124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Select a specific data point from the test dataset\n",
    "test_index = 0  # Change this index to the specific data point you want to summarize\n",
    "example_text = dataset[\"test\"][test_index][\"document\"]\n",
    "\n",
    "# Preprocess the input text\n",
    "input_text = \"summarize: \" + example_text\n",
    "inputs = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "inputs = inputs.to(device)\n",
    "# Generate the summary\n",
    "summary_ids = model.generate(inputs, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "\n",
    "# Decode the generated summary\n",
    "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Original Text:\\n\", example_text)\n",
    "print(\"\\nGenerated Summary:\\n\", summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
